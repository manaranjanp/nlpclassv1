{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:Anaconda3]",
      "language": "python",
      "name": "conda-env-Anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Topic Modelling.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvFDZfHDEe7J"
      },
      "source": [
        "### Topic Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ8GS37oEe7L"
      },
      "source": [
        "This notebook demonstrates data preprocessing as well as web based Visualization using pyLDAvis while doing topic modelling using gensim LDA algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "4QzOpxoWXbNV",
        "outputId": "096fc245-f7cb-4ba1-e4e8-8b11c4141fcb"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a5/15a0da6b0150b8b68610cc78af80364a80a9a4c8b6dd5ee549b8989d4b60/pyLDAvis-3.3.1.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 6.9MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Collecting numpy>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/03/c3526fb4e79a793498829ca570f2f868204ad9a8040afcd72d82a8f121db/numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7MB 383kB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/44/52/5cf7401456a461e4b481650dfb8279bc000f31a011d0918904f86e755947/funcy-1.16-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Collecting pandas>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/0a/90da8840e044c329a0271fb0244ff40a68a2615bc360c296a3dc5e326ab6/pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-cp37-none-any.whl size=136897 sha256=8a1e2dd7c49d609c9da543f0c41e5c9cdb73fcc22dd218b6897022177d886671\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/9c/fc/c6e00689d35c82cf96a8adc70edfe7ba7904374fdac3240ac2\n",
            "Successfully built pyLDAvis\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, funcy, pandas, pyLDAvis\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "Successfully installed funcy-1.16 numpy-1.21.0 pandas-1.2.5 pyLDAvis-3.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJR6xntZQbd8"
      },
      "source": [
        "## Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUdDl97Qak7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews_df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=10dXjNNV9dbkn5shYLPcKXk_FWHvLmbGT\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aExlfsJ7Qmzx"
      },
      "source": [
        "pd.set_option(\"max_colwidth\", 200)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "F9IEZIm3Qi-4",
        "outputId": "41f6d9fa-77ac-44c3-db2f-d993c94c3b87"
      },
      "source": [
        "reviews_df.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mmax_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mmax_colwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_colwidth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mshow_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.show_dimensions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.expand_frame_repr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_console_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_html\u001b[0;34m(self, buf, encoding, classes, notebook, border)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mnotebook\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0mWhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mHTML\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0mborder\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mborder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mborder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mincluded\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mopening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NotebookFormatter' object has no attribute 'get_result'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                              review  sentiment\n",
              "4493                                                                                             awesome  I really loved their services n food tqqqq          1\n",
              "4530                                                                                                                                     yummy foood          1\n",
              "1210                                                                                                               Quality wasnt good waste of money          0\n",
              "2461  Good place to visit with friends Price of food is little bit high but taste is good\\nI ordered pasta shake fish and chips and fries Must visit          1\n",
              "500       Worst restaurant 2rs bun coupled with 2 tomatoes and 2 cucumber and theyll charge you 130 Avoid at any cost even if youre extremely hungry          0\n",
              "3997                                                                                                                                             NaN          1\n",
              "2878                                                                                                                                      good taste          1\n",
              "4032  Very good sheesha and the pasta creamy garlic too cheesy its Soo yummy the fish grilled cheese fish ufff Soo yummy food addicted to this place          1\n",
              "4393                                                                                                                    They sent some other product          0\n",
              "206                                                                                                                                            great          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VtjoiZKQzOd",
        "outputId": "6da28d9b-60ee-43c3-c5bf-6d5ac29c3d66"
      },
      "source": [
        "reviews_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5476 entries, 0 to 5475\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     5322 non-null   object\n",
            " 1   sentiment  5476 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 85.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJlbmKsyQ2H_"
      },
      "source": [
        "reviews_df = reviews_df.dropna()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kv2OMtMQ7fm",
        "outputId": "27fb646e-2a23-456d-f995-7a2be87d1a90"
      },
      "source": [
        "reviews_df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5322 entries, 0 to 5475\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     5322 non-null   object\n",
            " 1   sentiment  5322 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 124.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2J6GCxaEe7L"
      },
      "source": [
        "##### Download NLTK Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI1Ah_mAXkV3"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcY1VFm9QEkh",
        "outputId": "2c74399f-dc54-4939-d3db-e8699662de62"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tcwt0RMEe7L"
      },
      "source": [
        "##### Clean Text and return Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67FXJd1eEe7L"
      },
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "tokenizer_w = WhitespaceTokenizer()\n",
        "\n",
        "def tokenize(text):\n",
        "    tokenized_list = tokenizer_w.tokenize(text.lower())   \n",
        "    return tokenized_list"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSPV7uOvEe7M"
      },
      "source": [
        "##### wordnet and lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X8DvRPNEe7N"
      },
      "source": [
        "Use NLTK's wordnet to find meanings of words, synonyms, antonyms, and more. In addition, we use WordNetLemmatizer to get the root word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe5HFXiCEe7N"
      },
      "source": [
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "def get_lemma(word):\n",
        "    return WordNetLemmatizer().lemmatize(word)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnY_V8j2Ee7O"
      },
      "source": [
        "##### Filter out stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVw3IitkEe7O"
      },
      "source": [
        "import nltk\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEEtBnfqEe7O"
      },
      "source": [
        "##### Define a function to prepare Text for Topic Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhk6oNUJQOoh"
      },
      "source": [
        "min_token_length = 3"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPAdR0_XEe7O"
      },
      "source": [
        "def prepare_text_for_lda(text):\n",
        "    tokens = tokenize(text)\n",
        "    tokens = [token for token in tokens if len(token) > min_token_length]\n",
        "    tokens = [token for token in tokens if token not in en_stop]\n",
        "    tokens = [get_lemma(token) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lw0XHOxEe7P"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBe6vwzaRBW9"
      },
      "source": [
        "reviews_tokens = reviews_df[reviews_df.sentiment == 1].review.map(lambda x: prepare_text_for_lda(x))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGt0Zr07Snmf",
        "outputId": "b458c698-da97-40d4-cbf1-045df29c331b"
      },
      "source": [
        "reviews_tokens[0:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1                [small, beautiful, place, really, loved, everything, beautiful, loved, every, visited, church, street, lasagna]\n",
              "3                                                                                                                         [good]\n",
              "5    [best, place, sunday, breakfast, always, crowded, need, wait, scrumptious, food, homely, environment, become, sunday, adda]\n",
              "6                          [thai, curry, dont, evidence, tiramisu, okay, better, cozy, nice, place, good, music, nice, location]\n",
              "7                           [calm, peaceful, place, good, choice, date, ambiance, good, loved, coffee, italian, dish, delicious]\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9Nr0VKEe7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3470f5e8-51d9-4e5e-8a41-1de6e42ffe21"
      },
      "source": [
        "len(reviews_tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-xA9Ne9Ee7R"
      },
      "source": [
        "##### LDA with gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo_nQPe-Ee7S"
      },
      "source": [
        "First, we are creating a dictionary from the data, then convert to bag-of-words corpus and save the dictionary and corpus for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fucXFYMWEe7S"
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(reviews_tokens)\n",
        "corpus = [dictionary.doc2bow(text) for text in reviews_tokens]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-bhY4GnEe7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "335b61ab-fc9d-4680-e0a1-1b5a6b1158d2"
      },
      "source": [
        "dictionary[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'beautiful'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMb_APnZEe7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad933a0-da8e-4b4f-ff6e-fb0c90b678d8"
      },
      "source": [
        "len(dictionary)  # total tokens"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2891AGqEe7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6977842c-8478-47f1-fda1-65f7cf9ed689"
      },
      "source": [
        "corpus[0:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 2),\n",
              "  (1, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 2),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (8, 1),\n",
              "  (9, 1),\n",
              "  (10, 1)],\n",
              " [(11, 1)],\n",
              " [(6, 1),\n",
              "  (12, 1),\n",
              "  (13, 1),\n",
              "  (14, 1),\n",
              "  (15, 1),\n",
              "  (16, 1),\n",
              "  (17, 1),\n",
              "  (18, 1),\n",
              "  (19, 1),\n",
              "  (20, 1),\n",
              "  (21, 1),\n",
              "  (22, 1),\n",
              "  (23, 2),\n",
              "  (24, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (32, 2),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (35, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (36, 1),\n",
              "  (37, 1),\n",
              "  (38, 1),\n",
              "  (39, 1),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (42, 1),\n",
              "  (43, 1),\n",
              "  (44, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1WDww3juS-sg",
        "outputId": "c8fafce6-d48e-447c-925a-59b663386f99"
      },
      "source": [
        "dictionary.id2token[3]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'everything'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DYbjxke8TMmw",
        "outputId": "05ad8851-3cd8-42b8-a6f8-9369cb2c9147"
      },
      "source": [
        "dictionary.id2token[8]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'small'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMcWixdpEe7U"
      },
      "source": [
        "# save corpus and dictionary to disk so that we can use it later during visualization\n",
        "import pickle\n",
        "\n",
        "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
        "dictionary.save('dictionary.gensim')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhG81-PVEe7V"
      },
      "source": [
        "##### Ask LDA to find 5 topics from the given data. Takes about 1 minute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BTCa0OBEe7V"
      },
      "source": [
        "import gensim\n",
        "\n",
        "NUM_TOPICS = 5\n",
        "\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHruO1v5TisS"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQrnQjvETkZc"
      },
      "source": [
        "ldamodel.save('review_topics.gensim')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JvREETgEe7V"
      },
      "source": [
        "###### Focus on Topics and Let us see top 4 words in each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRnwabqfEe7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba84450-bcfe-4006-c708-d833acc0e7b9"
      },
      "source": [
        "topics = ldamodel.print_topics(num_words=6)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.136*\"good\" + 0.049*\"place\" + 0.041*\"food\" + 0.019*\"taste\" + 0.018*\"nice\" + 0.018*\"ambience\"')\n",
            "(1, '0.048*\"awesome\" + 0.033*\"great\" + 0.031*\"food\" + 0.027*\"place\" + 0.026*\"burger\" + 0.024*\"cafe\"')\n",
            "(2, '0.090*\"place\" + 0.041*\"food\" + 0.027*\"loved\" + 0.023*\"good\" + 0.021*\"ambience\" + 0.019*\"really\"')\n",
            "(3, '0.044*\"place\" + 0.041*\"nice\" + 0.035*\"food\" + 0.030*\"amazing\" + 0.029*\"great\" + 0.024*\"cafe\"')\n",
            "(4, '0.078*\"good\" + 0.053*\"place\" + 0.051*\"food\" + 0.047*\"service\" + 0.038*\"great\" + 0.035*\"nice\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpC2w_3dEe7W"
      },
      "source": [
        "With LDA, we can see how words contribute to make each topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKwG1pbfEe7W"
      },
      "source": [
        "##### Test with a new document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDOJyAOfEe7W"
      },
      "source": [
        "Find out topic distribution for a given document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NlAUbgHIEe7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef02a50e-6dd0-4de7-8880-88b476373ab6"
      },
      "source": [
        "new_doc = 'The cofee tasted good, but the place is not pathetic'\n",
        "new_doc = prepare_text_for_lda(new_doc)\n",
        "new_doc_bow = dictionary.doc2bow(new_doc)\n",
        "print(new_doc_bow)\n",
        "print(ldamodel.get_document_topics(new_doc_bow))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(6, 1), (467, 1)]\n",
            "[(0, 0.067850046), (1, 0.0672918), (2, 0.069163986), (3, 0.7277469), (4, 0.067947276)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fP09yRVEe7X"
      },
      "source": [
        "Above new document is about machine learning algorithms, the LDA output shows that certain topic has the highest probability assigned, and some other topic has the second highest and some other topic the least.t probability assigned. We agreed!\n",
        "Remember that the above 5 probabilities add up to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJCNbIgEe7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd18fbd3-d5e5-446c-c6ee-08e020c55e3b"
      },
      "source": [
        "dictionary[1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'church'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efyPCrwwEe7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45cfaf8b-7bd1-40fa-b0da-54bc9c5deb4b"
      },
      "source": [
        "dictionary[9]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'street'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YfRwSuPEe7Y"
      },
      "source": [
        "Instead of 5 topics let us ask LDA to find just 3 topics in the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgaiXugREe7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4263266d-a2e9-483f-fc9f-a9f27fc480cb"
      },
      "source": [
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 3, id2word=dictionary, passes=15)\n",
        "ldamodel.save('topics_3.gensim')\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.064*\"food\" + 0.061*\"place\" + 0.031*\"good\" + 0.022*\"nice\"')\n",
            "(1, '0.103*\"good\" + 0.055*\"place\" + 0.035*\"food\" + 0.034*\"really\"')\n",
            "(2, '0.073*\"good\" + 0.050*\"place\" + 0.033*\"nice\" + 0.025*\"great\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz7kghbMEe7Z"
      },
      "source": [
        "##### Visualization using pyLDAvis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FavQSmvBEe7Z"
      },
      "source": [
        "pyLDAvis is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data.\n",
        "\n",
        "The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pERf_fzOEe7Z"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
        "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
        "lda = gensim.models.ldamodel.LdaModel.load('review_topics.gensim')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYfPkZigEe7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "6cd560e1-ad42-4f7a-bc7f-2ea904bdf3f3"
      },
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "lda_display = gensimvis.prepare(lda, corpus, dictionary, sort_topics=False)\n",
        "lda_display"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-05fe50ea1105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlda_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlda_display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m    122\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    439\u001b[0m     topic_info = _topic_info(topic_term_dists, topic_proportion,\n\u001b[1;32m    440\u001b[0m                              \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                              n_jobs, start_index)\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mtoken_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_token_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mtopic_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_topic_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# this determines the R terms that are displayed when no topic is selected.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mtt_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mtopic_given_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"topic_term_dists / tt_sum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0mlog_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"topic_given_term.T / topic_proportion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"topic_given_term * log_1.T\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;34m\"multi-line expressions are only valid in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;34m\"context of data, use DataFrame.eval\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         )\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0m_check_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36m_check_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mEngine\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_NUMEXPR_INSTALLED' from 'pandas.core.computation.check' (/usr/local/lib/python3.7/dist-packages/pandas/core/computation/check.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcbe9e2lEe7a"
      },
      "source": [
        "Saliency: a measure of how much the term tells you about the topic.\n",
        "\n",
        "Relevance: a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n",
        "\n",
        "The size of the bubble measures the importance of the topics, relative to the data.\n",
        "\n",
        "First, we got the most salient terms, means terms mostly tell us about what’s going on relative to the topics. We can also look at individual topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIMGEbdCZCeV"
      },
      "source": [
        "### Try with only the nouns\n",
        "\n",
        "<code>\n",
        "tags = nltk.pos_tag(tokenized_list)\n",
        "\n",
        "nouns = [word for word,pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "\n",
        "</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p57qo46ejiP9"
      },
      "source": [
        "## Topic Modelling using NMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OakhLU2ojofK"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "import numpy as np"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY2L9UKLkaTI"
      },
      "source": [
        "no_topics = 5 \n",
        "no_top_words = 4 \n",
        "no_top_documents = 3 "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRZvOyrcjlrS"
      },
      "source": [
        "# NMF is able to use tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(reviews_df.review)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT2D9_TQkg1Y"
      },
      "source": [
        "# Run NMF\n",
        "nmf_model = NMF(n_components=no_topics, random_state=1, init='nndsvd').fit(tfidf)\n",
        "nmf_W = nmf_model.transform(tfidf)\n",
        "nmf_H = nmf_model.components_"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFJlHbNrO1Fh",
        "outputId": "5626df54-2ce8-4724-a831-da9d90664239"
      },
      "source": [
        "tfidf.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5322, 1318)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTe31AU_O3bI",
        "outputId": "47232f6a-a8fc-4709-aa7a-85c2025173dc"
      },
      "source": [
        "nmf_W.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5322, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6upKLNGvOpWr",
        "outputId": "f27a5086-8197-4489-d165-68f7e44059ee"
      },
      "source": [
        "nmf_H.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1318)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPiip1VkQGp"
      },
      "source": [
        "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
        "    for topic_idx, topic in enumerate(H):\n",
        "        print(\"Topic %d:\" % (topic_idx))\n",
        "        print(\"Topic Words:\", \" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
        "        print(\"----------------------------------------------------------------------\")        \n",
        "        print(\"Some documents that contain this topic are:\")\n",
        "        print(\"----------------------------------------------------------------------\")        \n",
        "        for doc_index in top_doc_indices:\n",
        "            print(documents[doc_index])\n",
        "        print(\"----------------------------------------------------------------------\")        \n",
        "        print(\"----------------------------------------------------------------------\")                "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwh7pBTEkUDw",
        "outputId": "968b70cf-940f-409f-dafb-710b3d993190"
      },
      "source": [
        "print(\"NMF Topics\")\n",
        "display_topics(nmf_H, nmf_W, tfidf_feature_names, reviews_df.review, no_top_words, no_top_documents)\n",
        "print(\"--------------\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMF Topics\n",
            "Topic 0:\n",
            "Topic Words: good taste wasnt food\n",
            "----------------------------------------------------------------------\n",
            "Some documents that contain this topic are:\n",
            "----------------------------------------------------------------------\n",
            "not bad\n",
            "I didnt get the food i ordered\n",
            "the choco lava cake was cold very disappointing\n",
            "=======================================================================\n",
            "Topic 1:\n",
            "Topic Words: bad taste quality pizza\n",
            "----------------------------------------------------------------------\n",
            "Some documents that contain this topic are:\n",
            "----------------------------------------------------------------------\n",
            "taste and even the packing of the food is good\n",
            "Nothing above average tbh  coffee shake is trash  delivery was horrendous\n",
            "not bad\n",
            "=======================================================================\n",
            "Topic 2:\n",
            "Topic Words: great place food nice\n",
            "----------------------------------------------------------------------\n",
            "Some documents that contain this topic are:\n",
            "----------------------------------------------------------------------\n",
            "bad quality\n",
            "Much needed place in ORR has a great ambience The staff r too friendly and down to earth Awesome food Best place to hangout with friends\n",
            "Mouth watering pizza Very affordable with zomato gold Dedicated staff is present Would love to visit this place again Nice ambience\n",
            "=======================================================================\n",
            "Topic 3:\n",
            "Topic Words: delivered ordered order food\n",
            "----------------------------------------------------------------------\n",
            "Some documents that contain this topic are:\n",
            "----------------------------------------------------------------------\n",
            "We ordered all American burger and sandwiches it was not cooked properly The taste was bad\n",
            "Dont ever order from this place\n",
            "Its too pricey too\n",
            "the food wasnt good\n",
            "Food is very yummy enjoyed a lot here very specious restaurant probably the best in this locality in terms of quality and also economic tooo thanks\n",
            "=======================================================================\n",
            "Topic 4:\n",
            "Topic Words: veg non smell spicy\n",
            "----------------------------------------------------------------------\n",
            "Some documents that contain this topic are:\n",
            "----------------------------------------------------------------------\n",
            "Ordered garlic rice with kadai panner Food was inedible They share fake post by them self for a hype Waste of time n money Eat at ur own risk\n",
            "Nice little cafe Very friendly staff Food is nice as well Would recommend baba black sheep burger as well as white truffle cafe in desserts\n",
            "Nothing above average tbh  coffee shake is trash  delivery was horrendous\n",
            "=======================================================================\n",
            "--------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_3ZXt1pEe7b"
      },
      "source": [
        "### Exercise for participants\n",
        "\n",
        "- Try to model topics only for Positive sentiments\n",
        "- Try to model topics only for Negative sentiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV1OnlVRUiqt"
      },
      "source": [
        "### References\n",
        "\n",
        "- https://towardsdatascience.com/setting-up-text-preprocessing-pipeline-using-scikit-learn-and-spacy-e09b9b76758f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh25Fsf-Ukuh"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-vBjrPtjhjp"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}